{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 459209,
          "sourceType": "datasetVersion",
          "datasetId": 210524
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "CycleGAN",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/modi2009/ComputerVision/blob/GANS/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "suyashdamle_cyclegan_path = kagglehub.dataset_download('suyashdamle/cyclegan')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "trKwS3UImgi3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import important libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.utils import save_image\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:37:56.44348Z",
          "iopub.execute_input": "2025-05-03T22:37:56.443776Z",
          "iopub.status.idle": "2025-05-03T22:37:56.448673Z",
          "shell.execute_reply.started": "2025-05-03T22:37:56.44375Z",
          "shell.execute_reply": "2025-05-03T22:37:56.447918Z"
        },
        "id": "Y22Thbjhmgi5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discriminator**"
      ],
      "metadata": {
        "id": "E7hZYR0lmgi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Convolutional Block function\n",
        "def Conv2D(in_channels, out_channels,kernel_size = 4, stride = 2, padding = 1, padding_mode = 'reflect', dropout = 0):\n",
        "  layer = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, padding_mode = padding_mode, bias = True),\n",
        "      nn.InstanceNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2),\n",
        "  )\n",
        "  return layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:15:13.230857Z",
          "iopub.execute_input": "2025-05-03T22:15:13.231571Z",
          "iopub.status.idle": "2025-05-03T22:15:13.235565Z",
          "shell.execute_reply.started": "2025-05-03T22:15:13.23154Z",
          "shell.execute_reply": "2025-05-03T22:15:13.234951Z"
        },
        "id": "-Gi38H6_mgi7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels = 3, features = [64,128,256,512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features[0], kernel_size = 4, stride = 2, padding = 1, padding_mode = 'reflect'),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layer = Conv2D(in_channels, feature, stride = 1 if feature == features[-1] else 2)\n",
        "            layers.append(layer)\n",
        "            in_channels = feature\n",
        "\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels, 1, kernel_size = 4, stride = 1, padding = 1 , padding_mode = 'reflect'\n",
        "            )\n",
        "        )\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.model(x)\n",
        "        return torch.sigmoid(x)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:15:16.892091Z",
          "iopub.execute_input": "2025-05-03T22:15:16.892774Z",
          "iopub.status.idle": "2025-05-03T22:15:16.898586Z",
          "shell.execute_reply.started": "2025-05-03T22:15:16.89275Z",
          "shell.execute_reply": "2025-05-03T22:15:16.897783Z"
        },
        "id": "PeZqq0igmgi8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def testDiscriminator():\n",
        "    x = torch.randn((1, 3, 256, 256))\n",
        "    model = Discriminator()\n",
        "    for param in model.parameters():\n",
        "        print(param.dtype)  # Should output torch.float16 for mixed precision\n",
        "    preds = model(x)\n",
        "    return preds.shape\n",
        "testDiscriminator()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:25:31.034686Z",
          "iopub.execute_input": "2025-05-03T22:25:31.035224Z",
          "iopub.status.idle": "2025-05-03T22:25:31.118376Z",
          "shell.execute_reply.started": "2025-05-03T22:25:31.035196Z",
          "shell.execute_reply": "2025-05-03T22:25:31.117674Z"
        },
        "id": "EQ8p7XEdmgi8",
        "outputId": "b7253d6f-ca10-4918-b71d-92244f7cb8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.float32\ntorch.float32\ntorch.float32\ntorch.float32\ntorch.float32\ntorch.float32\ntorch.float32\ntorch.float32\ntorch.float32\ntorch.float32\n",
          "output_type": "stream"
        },
        {
          "execution_count": 65,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([1, 1, 30, 30])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generator**"
      ],
      "metadata": {
        "id": "1nrQ1BlKmgi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Convolutional Transpose Block function\n",
        "def ConvTranspose2D(num_channel, out_channels,kernel_size = 4, stride = 2, padding = 1):\n",
        "  layer = nn.Sequential(\n",
        "      nn.ConvTranspose2d(num_channel, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, output_padding = 1),\n",
        "      nn.InstanceNorm2d(out_channels),\n",
        "      nn.ReLU(True),\n",
        "  )\n",
        "  return layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:25:38.566068Z",
          "iopub.execute_input": "2025-05-03T22:25:38.566843Z",
          "iopub.status.idle": "2025-05-03T22:25:38.571055Z",
          "shell.execute_reply.started": "2025-05-03T22:25:38.5668Z",
          "shell.execute_reply": "2025-05-03T22:25:38.570357Z"
        },
        "id": "vUaT73PZmgi-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Convolutional Block function\n",
        "def Conv2DGen(in_channels, out_channels,use_act = True, kernel_size = 4, stride = 2, padding = 1, padding_mode = 'reflect', dropout = 0):\n",
        "  layer = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, padding_mode = padding_mode, bias = True),\n",
        "      nn.InstanceNorm2d(out_channels),\n",
        "      nn.ReLU(True) if use_act else nn.Identity(),\n",
        "  )\n",
        "  return layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:25:39.15839Z",
          "iopub.execute_input": "2025-05-03T22:25:39.158658Z",
          "iopub.status.idle": "2025-05-03T22:25:39.163251Z",
          "shell.execute_reply.started": "2025-05-03T22:25:39.158638Z",
          "shell.execute_reply": "2025-05-03T22:25:39.162623Z"
        },
        "id": "lnMZ5e-lmgi-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def ResidualBlock(in_channels):\n",
        "    layer = nn.Sequential(\n",
        "        Conv2DGen(in_channels, in_channels, kernel_size = 3, padding = 1,stride = 1),\n",
        "        Conv2DGen(in_channels, in_channels, use_act= False, kernel_size = 3, padding = 1,stride = 1)\n",
        "    )\n",
        "    return layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:25:39.55591Z",
          "iopub.execute_input": "2025-05-03T22:25:39.556197Z",
          "iopub.status.idle": "2025-05-03T22:25:39.560387Z",
          "shell.execute_reply.started": "2025-05-03T22:25:39.556175Z",
          "shell.execute_reply": "2025-05-03T22:25:39.55981Z"
        },
        "id": "U9ZkZZDSmgi_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Discriminator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels = 3, features = [64,128], num_residuals = 9):\n",
        "        super().__init__()\n",
        "\n",
        "        # create encoder\n",
        "\n",
        "        # create initial layer of encoder\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features[0], kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect'),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # Create down blocks\n",
        "        self.layers_down = nn.ModuleList()\n",
        "        for feature in features:\n",
        "            layer = Conv2DGen(feature, feature*2, kernel_size = 3, padding = 1, stride = 2)\n",
        "            self.layers_down.append(layer)\n",
        "\n",
        "\n",
        "        # create residual block\n",
        "        self.residual_blocks = nn.ModuleList(\n",
        "            [ResidualBlock(features[-1]*2) for _ in range(num_residuals)]\n",
        "        )\n",
        "\n",
        "        # creatue upsampling blocks\n",
        "        self.layers_up = nn.ModuleList()\n",
        "        features_reversed = reversed(features)\n",
        "        for feature in features_reversed:\n",
        "            layer = ConvTranspose2D(feature*2, feature, kernel_size = 3, padding = 1, stride = 2)\n",
        "            self.layers_up.append(layer)\n",
        "\n",
        "        # last layer\n",
        "        self.last_layer = nn.Sequential(\n",
        "            nn.Conv2d(features[0], in_channels, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect'),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_down(x)\n",
        "        for layer in self.layers_down:\n",
        "            x = layer(x)\n",
        "        for layer in self.residual_blocks:\n",
        "            x = layer(x) + x\n",
        "        for layer in self.layers_up:\n",
        "            x = layer(x)\n",
        "        x = self.last_layer(x)\n",
        "\n",
        "        return torch.tanh(x)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:25:42.192447Z",
          "iopub.execute_input": "2025-05-03T22:25:42.192757Z",
          "iopub.status.idle": "2025-05-03T22:25:42.200302Z",
          "shell.execute_reply.started": "2025-05-03T22:25:42.192735Z",
          "shell.execute_reply": "2025-05-03T22:25:42.199591Z"
        },
        "id": "9513TSx1mgi_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def testGenerator():\n",
        "    x = torch.randn((2, 3, 256, 256))\n",
        "    model = Generator()\n",
        "    preds = model(x)\n",
        "    return preds.shape\n",
        "testGenerator()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:25:42.397454Z",
          "iopub.execute_input": "2025-05-03T22:25:42.398083Z",
          "iopub.status.idle": "2025-05-03T22:25:43.892978Z",
          "shell.execute_reply.started": "2025-05-03T22:25:42.398053Z",
          "shell.execute_reply": "2025-05-03T22:25:43.892234Z"
        },
        "id": "U_UteVGCmgjA",
        "outputId": "1519470f-f5cd-4b6e-8ec6-0915e28bf146"
      },
      "outputs": [
        {
          "execution_count": 70,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([2, 3, 256, 256])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and Augment Dataset**"
      ],
      "metadata": {
        "id": "IA2cE-SMmgjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MapDataset(Dataset):\n",
        "    def __init__(self, root_zebra, root_horse, transform):\n",
        "        self.root_zebra = root_zebra\n",
        "        self.root_horse = root_horse\n",
        "        self.transform = transform\n",
        "\n",
        "        self.zebra_images = os.listdir(root_zebra)\n",
        "        self.horse_images = os.listdir(root_horse)\n",
        "\n",
        "        self.length_zebra = len(self.zebra_images)\n",
        "        self.length_horse = len(self.horse_images)\n",
        "        self.length_dataset = max(self.length_zebra, self.length_horse)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        zebra_image = self.zebra_images[idx % self.length_zebra]\n",
        "        horse_image = self.horse_images[idx % self.length_horse]\n",
        "\n",
        "        zebra_path = os.path.join(self.root_zebra, zebra_image)\n",
        "        horse_path = os.path.join(self.root_horse, horse_image)\n",
        "\n",
        "        zebra_image = np.array(Image.open(zebra_path).convert('RGB'))\n",
        "        horse_image = np.array(Image.open(horse_path).convert('RGB'))\n",
        "\n",
        "                # Apply transformations\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=zebra_image, image0=horse_image)\n",
        "            zebra_image = augmented[\"image\"]\n",
        "            horse_image = augmented[\"image0\"]\n",
        "\n",
        "\n",
        "\n",
        "        return zebra_image, horse_image\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:36.159849Z",
          "iopub.execute_input": "2025-05-03T22:44:36.16066Z",
          "iopub.status.idle": "2025-05-03T22:44:36.167057Z",
          "shell.execute_reply.started": "2025-05-03T22:44:36.16063Z",
          "shell.execute_reply": "2025-05-03T22:44:36.16633Z"
        },
        "id": "5s4ss9PZmgjA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(256.0,256.0),\n",
        "    A.Normalize([.5,.5,.5], [.5,.5,.5], max_pixel_value = 255.0),\n",
        "    ToTensorV2()\n",
        "],additional_targets = {'image0':'image'})\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:36.337567Z",
          "iopub.execute_input": "2025-05-03T22:44:36.337808Z",
          "iopub.status.idle": "2025-05-03T22:44:36.344391Z",
          "shell.execute_reply.started": "2025-05-03T22:44:36.337792Z",
          "shell.execute_reply": "2025-05-03T22:44:36.343661Z"
        },
        "id": "u1INWosWmgjB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "NUM_WORKERS = 4\n",
        "# Load data and create DataLoader\n",
        "train_dataset = MapDataset(\n",
        "    root_zebra='/kaggle/input/cyclegan/horse2zebra/horse2zebra/trainB',\n",
        "    root_horse = '/kaggle/input/cyclegan/horse2zebra/horse2zebra/trainA',\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "val_dataset = MapDataset(\n",
        "    root_zebra='/kaggle/input/cyclegan/horse2zebra/horse2zebra/testB',\n",
        "    root_horse = '/kaggle/input/cyclegan/horse2zebra/horse2zebra/testA',\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:36.525508Z",
          "iopub.execute_input": "2025-05-03T22:44:36.526124Z",
          "iopub.status.idle": "2025-05-03T22:44:36.536149Z",
          "shell.execute_reply.started": "2025-05-03T22:44:36.5261Z",
          "shell.execute_reply": "2025-05-03T22:44:36.535468Z"
        },
        "id": "2aiQfa-MmgjB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('images', exist_ok = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:36.678674Z",
          "iopub.execute_input": "2025-05-03T22:44:36.679004Z",
          "iopub.status.idle": "2025-05-03T22:44:36.682895Z",
          "shell.execute_reply.started": "2025-05-03T22:44:36.678979Z",
          "shell.execute_reply": "2025-05-03T22:44:36.682257Z"
        },
        "id": "w_POpOeCmgjB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Loss Functions**"
      ],
      "metadata": {
        "id": "4_rAVenzmgjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize criterion loss\n",
        "criterion = nn.MSELoss()\n",
        "L1_LOSS = nn.L1Loss()\n",
        "# discriminator loss function\n",
        "def discriminator_loss(real_preds, fake_preds):\n",
        "  # initialize targets\n",
        "  target_true = torch.ones_like(real_preds)\n",
        "  target_false = torch.zeros_like(fake_preds)\n",
        "\n",
        "  # compute losses\n",
        "  real_loss = criterion(real_preds, target_true)\n",
        "  fake_loss = criterion(fake_preds, target_false)\n",
        "\n",
        "  return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_preds, image, cycle_image, identity_image, lamda_cycle, lamdia_I):\n",
        "\n",
        "  # initialize target\n",
        "  target_true = torch.ones_like(fake_preds)\n",
        "\n",
        "  # compute loss\n",
        "  gen_loss = criterion(fake_preds, target_true)\n",
        "  cycle_loss = L1_LOSS(image, cycle_image) * lamda_cycle\n",
        "  identity_loss = L1_LOSS(image, identity_image) * lamdia_I\n",
        "  return gen_loss + cycle_loss + identity_loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:37.004754Z",
          "iopub.execute_input": "2025-05-03T22:44:37.005655Z",
          "iopub.status.idle": "2025-05-03T22:44:37.010652Z",
          "shell.execute_reply.started": "2025-05-03T22:44:37.00563Z",
          "shell.execute_reply": "2025-05-03T22:44:37.010044Z"
        },
        "id": "xIUfi0NLmgjB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**"
      ],
      "metadata": {
        "id": "KwLZ2JMumgjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Hyperparameters\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LEARNING_RATE = 2e-4\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS_IMAGE = 3\n",
        "LAMDA_CYCLE = 10\n",
        "LAMDA_I = 0.0\n",
        "NUM_EPOCH = 200\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:38.702703Z",
          "iopub.execute_input": "2025-05-03T22:44:38.702967Z",
          "iopub.status.idle": "2025-05-03T22:44:38.706942Z",
          "shell.execute_reply.started": "2025-05-03T22:44:38.702946Z",
          "shell.execute_reply": "2025-05-03T22:44:38.706196Z"
        },
        "id": "5hnkerrmmgjC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Models\n",
        "disc_h = Discriminator(CHANNELS_IMAGE).to(DEVICE)\n",
        "disc_z = Discriminator(CHANNELS_IMAGE).to(DEVICE)\n",
        "gen_h = Generator(CHANNELS_IMAGE).to(DEVICE)\n",
        "gen_z= Generator(CHANNELS_IMAGE).to(DEVICE)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:40.40893Z",
          "iopub.execute_input": "2025-05-03T22:44:40.409206Z",
          "iopub.status.idle": "2025-05-03T22:44:40.646213Z",
          "shell.execute_reply.started": "2025-05-03T22:44:40.409185Z",
          "shell.execute_reply": "2025-05-03T22:44:40.645638Z"
        },
        "id": "sJ6PZacdmgjC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Initialize Optimizer\n",
        "opt_disc = optim.Adam(\n",
        "    list(disc_h.parameters()) + list(disc_z.parameters()),\n",
        "    lr = LEARNING_RATE,\n",
        "    betas =(0.5,.999)\n",
        ")\n",
        "\n",
        "opt_gen = opt_disc = optim.Adam(\n",
        "    list(gen_h.parameters()) + list(gen_z.parameters()),\n",
        "    lr = LEARNING_RATE,\n",
        "    betas =(0.5,.999)\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:44:40.647207Z",
          "iopub.execute_input": "2025-05-03T22:44:40.647436Z",
          "iopub.status.idle": "2025-05-03T22:44:40.652332Z",
          "shell.execute_reply.started": "2025-05-03T22:44:40.64741Z",
          "shell.execute_reply": "2025-05-03T22:44:40.651632Z"
        },
        "id": "jofTbqmmmgjC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "def train(num_epochs,disc_h, disc_z, gen_h, gen_z, loader, opt_disc, opt_gen, lamda_cycle, lamda_I,device):\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss_disc = 0  # Accumulate discriminator loss for the epoch\n",
        "        epoch_loss_gen = 0   # Accumulate generator loss for the epoch\n",
        "        with tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as t:\n",
        "            for idx, (zebra, horse) in enumerate(t):\n",
        "                zebra = zebra.to(device)\n",
        "                horse = horse.to(device)\n",
        "\n",
        "                # Train Discriminator\n",
        "\n",
        "\n",
        "                # Train Discriminator of horse\n",
        "                fake_horse = gen_h(zebra)\n",
        "                D_h_real = disc_h(horse)\n",
        "                D_h_fake = disc_h(fake_horse.detach())\n",
        "                D_h_loss = discriminator_loss(D_h_real, D_h_fake)\n",
        "\n",
        "                # Train Discriminator of zebra\n",
        "                fake_zebra = gen_z(horse)\n",
        "                D_z_real = disc_z(zebra)\n",
        "                D_z_fake = disc_z(fake_zebra.detach())\n",
        "                D_z_loss = discriminator_loss(D_z_real, D_z_fake)\n",
        "\n",
        "                D_loss = (D_h_loss + D_z_loss)/2\n",
        "\n",
        "\n",
        "\n",
        "                opt_disc.zero_grad()\n",
        "                D_loss.backward()\n",
        "                opt_disc.step()\n",
        "                epoch_loss_disc += D_loss.item()\n",
        "\n",
        "\n",
        "                # Train Generator\n",
        "\n",
        "\n",
        "                # Train Generator of horse\n",
        "                gen_h_fake = disc_h(fake_horse)\n",
        "                cycle_horse = gen_h(fake_zebra)\n",
        "                identitiy_horse = gen_h(horse)\n",
        "                gen_h_loss = generator_loss(gen_h_fake, horse, cycle_horse, identitiy_horse, lamda_cycle, lamda_I)\n",
        "\n",
        "                # Train Generator of zebra\n",
        "                gen_z_fake = disc_z(fake_zebra)\n",
        "                cycle_zebra = gen_z(fake_horse)\n",
        "                identitiy_zebra = gen_z(zebra)\n",
        "                gen_z_loss = generator_loss(gen_z_fake, zebra, cycle_zebra, identitiy_zebra, lamda_cycle, lamda_I)\n",
        "\n",
        "                G_loss = gen_h_loss + gen_z_loss\n",
        "\n",
        "\n",
        "                opt_gen.zero_grad()\n",
        "                G_loss.backward()\n",
        "                opt_gen.step()\n",
        "                epoch_loss_gen += G_loss.item()\n",
        "                t.set_postfix(d_loss=D_loss.item(), g_loss=G_loss.item())\n",
        "\n",
        "                if idx % 200 == 0:\n",
        "                    save_image(fake_horse*0.5 + 0.5, f\"/kaggle/working/images/horse_{idx}.png\")\n",
        "                    save_image(fake_zebra*0.5 + 0.5, f\"/kaggle/working/images/zebra_{idx}.png\")\n",
        "\n",
        "        # Average loss over all batches in the epoch\n",
        "        avg_loss_disc = epoch_loss_disc / len(loader)\n",
        "        avg_loss_gen = epoch_loss_gen / len(loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | \"f\"Avg D Loss: {avg_loss_disc:.4f} | Avg G Loss: {avg_loss_gen:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:45:13.783172Z",
          "iopub.execute_input": "2025-05-03T22:45:13.783427Z",
          "iopub.status.idle": "2025-05-03T22:45:13.792556Z",
          "shell.execute_reply.started": "2025-05-03T22:45:13.783406Z",
          "shell.execute_reply": "2025-05-03T22:45:13.791773Z"
        },
        "id": "JdfI1A_1mgjC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    NUM_EPOCH,disc_h, disc_z, gen_h, gen_z, train_loader, opt_disc, opt_gen, LAMDA_CYCLE, LAMDA_I,DEVICE\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-03T22:45:15.792382Z",
          "iopub.execute_input": "2025-05-03T22:45:15.792617Z"
        },
        "id": "MOJBFObhmgjD",
        "outputId": "45410d02-ef52-48b4-a814-9591d82e6c46",
        "colab": {
          "referenced_widgets": [
            "fe81fe7db07b4ca3b0faa153bc565e71",
            "9fe2c09c66d64040bc6285a510f63dcd",
            "a3bd6302366e42a88121d0349270e76a",
            "a1d78ed1249a46cd8b7cceb5a148bfed",
            "69a88dab4f364f1db712f9331ac317d6",
            "e881b7a1c20e4986a439c22946283a94",
            "fcd24855c44d406c856b1d399bd89b46",
            "4473841348c842e9a0500c6d042e0e1f",
            "413537730dc54fd5afba135ab8e50460",
            "860d5f1e9e334740bdcfee23bb843f1e",
            "6b32f9e365c041dea58f2378fcee31f1",
            "d07014adc9f4445289ef2d1af3f6ed51",
            "c9bfb0c0b1954f93bbaa3fbde9eae86d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 1/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe81fe7db07b4ca3b0faa153bc565e71"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [1/200] | Avg D Loss: 0.5398 | Avg G Loss: 5.0407\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 2/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fe2c09c66d64040bc6285a510f63dcd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [2/200] | Avg D Loss: 0.5395 | Avg G Loss: 3.9643\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 3/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3bd6302366e42a88121d0349270e76a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [3/200] | Avg D Loss: 0.5405 | Avg G Loss: 3.5973\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 4/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1d78ed1249a46cd8b7cceb5a148bfed"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [4/200] | Avg D Loss: 0.5413 | Avg G Loss: 3.3280\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 5/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69a88dab4f364f1db712f9331ac317d6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [5/200] | Avg D Loss: 0.5425 | Avg G Loss: 3.1456\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 6/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e881b7a1c20e4986a439c22946283a94"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [6/200] | Avg D Loss: 0.5432 | Avg G Loss: 2.9933\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 7/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcd24855c44d406c856b1d399bd89b46"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [7/200] | Avg D Loss: 0.5445 | Avg G Loss: 2.8674\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 8/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4473841348c842e9a0500c6d042e0e1f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [8/200] | Avg D Loss: 0.5460 | Avg G Loss: 2.7602\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 9/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "413537730dc54fd5afba135ab8e50460"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [9/200] | Avg D Loss: 0.5475 | Avg G Loss: 2.6291\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 10/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "860d5f1e9e334740bdcfee23bb843f1e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [10/200] | Avg D Loss: 0.5493 | Avg G Loss: 2.5635\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 11/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b32f9e365c041dea58f2378fcee31f1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [11/200] | Avg D Loss: 0.5508 | Avg G Loss: 2.4715\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 12/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d07014adc9f4445289ef2d1af3f6ed51"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [12/200] | Avg D Loss: 0.5523 | Avg G Loss: 2.4273\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 13/200:   0%|          | 0/334 [00:00<?, ?batch/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9bfb0c0b1954f93bbaa3fbde9eae86d"
            }
          },
          "metadata": {}
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/746995072.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLAMDA_CYCLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLAMDA_I\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m/tmp/ipykernel_31/2780904829.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, disc_h, disc_z, gen_h, gen_z, loader, opt_disc, opt_gen, lamda_cycle, lamda_I, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mepoch_loss_gen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "_4xK4H_EmgjD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "tKvjPXbnmgjD"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}